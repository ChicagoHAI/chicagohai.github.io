<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Chicago Human+AI Lab (CHAI) on Chicago Human+AI Lab</title><link>https://chicagohai.github.io/</link><description>Recent content in Chicago Human+AI Lab (CHAI) on Chicago Human+AI Lab</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sun, 13 Aug 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://chicagohai.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>A Symposium on Human+AI</title><link>https://chicagohai.github.io/news/230813-symposium-hai/</link><pubDate>Sun, 13 Aug 2023 00:00:00 +0000</pubDate><guid>https://chicagohai.github.io/news/230813-symposium-hai/</guid><description>September 29, 2023, 9:00 AM - 5:30 PM
John Crerar Library, Room 390
AI has achieved impressive success in a wide variety of domains, ranging from medical diagnosis to generative AI. This success provides rich opportunities for AI to address important societal challenges, but there are also growing concerns about the bias and harm that AI systems may cause. This conference brings together diverse perspectives to think about the best way for AI to fit into society and how to develop the best AI for humans.</description></item><item><title>New Paper on Active Example Selection</title><link>https://chicagohai.github.io/news/221212-active-example-selection/</link><pubDate>Mon, 12 Dec 2022 00:00:00 +0000</pubDate><guid>https://chicagohai.github.io/news/221212-active-example-selection/</guid><description>Checkout this blog post for our EMNLP 2022 paper Active Example Selection for In-Context Learning!</description></item><item><title>Human-Centered Evaluations of Explanations at NAACL 2022</title><link>https://chicagohai.github.io/news/220722-human-centered-eval-of-explanations-naacl-22/</link><pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate><guid>https://chicagohai.github.io/news/220722-human-centered-eval-of-explanations-naacl-22/</guid><description>We gave a tutorial on human-centered evaluation of explanations at NAACL, and the recorded videos are on YouTube!</description></item><item><title>Postdoc Position on Human-centered AI</title><link>https://chicagohai.github.io/news/220722-postdoc-hai/</link><pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate><guid>https://chicagohai.github.io/news/220722-postdoc-hai/</guid><description>We have a postdoc opening on human-centered AI. Please email Chenhao your CV and names of references!</description></item><item><title>Postdoc Position through DSI Fellowship</title><link>https://chicagohai.github.io/news/220722-dsi-fellowship/</link><pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate><guid>https://chicagohai.github.io/news/220722-dsi-fellowship/</guid><description>In Fall 2022, we will also have openings for postdocs through the DSI fellowship!</description></item><item><title>Demo Links</title><link>https://chicagohai.github.io/demos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://chicagohai.github.io/demos/</guid><description> Machine in the loop Retweetedmore Reddit genealogy Task delegability</description></item><item><title>People</title><link>https://chicagohai.github.io/people/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://chicagohai.github.io/people/</guid><description> Faculty Chenhao Tan PhDs Chao-Chun (Joe) Hsu Han Liu Yangqiaoyu (Rosa) Zhou Karen Zhou Chacha Chen Mourad Heddaya Masters &amp;amp; Undergrads Grace Wang Jiamin Yang Shuyuan (Lily) Wang Dang Nguyen Yixuan (Tom) Wang Yuxin (Jessica) Ji Miles Wang Tejes Srivastava Aditya Krishna</description></item><item><title>Publication</title><link>https://chicagohai.github.io/publication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://chicagohai.github.io/publication/</guid><description>Preprint Emre Kıcıman, Robert Ness, Amit Sharma, and Chenhao Tan. Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. Nan-Jiang Jiang, Chenhao Tan, and Marie-Catherine de Marneffe. Understanding and Predicting Human Label Variation in Natural Language Inference through Explanation. Himabindu Lakkaraju, Dylan Slack, Yuxin Chen, Chenhao Tan, and Sameer Singh. Rethinking Explainability as a Dialogue: A Practitioner&amp;rsquo;s Perspective. 2023 Karen Zhou and Chenhao Tan. Entity-Based Evaluation of Political Bias in Automatic Summarization.</description></item></channel></rss>