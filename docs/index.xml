<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Homepage on Chicago Human&#43;AI Lab (CHAI)</title>
    <link>https://chicagohai.github.io/</link>
    <description>Recent content in Homepage on Chicago Human&#43;AI Lab (CHAI)</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://chicagohai.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>About</title>
      <link>https://chicagohai.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chicagohai.github.io/about/</guid>
      <description>About Me  This is a Hugo based resume template. You can find the full source code on GitHub.
Research Interest Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam finibus ipsum ac erat aliquam dapibus. Vestibulum vehicula placerat ex, a consectetur odio pharetra quis1. Mauris id urna ante.
Fusce pharetra diam ac nisi aliquet, velegestas ex iaculis. Pellentesque laoreet cursus tellus sed pellentesque. Praesent a rhoncus elit2. Nunc ipsum nisl, consequat sit amet pretium quis, gravida id ipsum.</description>
    </item>
    
    <item>
      <title>Publication</title>
      <link>https://chicagohai.github.io/publication/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://chicagohai.github.io/publication/</guid>
      <description>Preprint
 Chenhao Tan. On the Diversity and Limits of Human Explanations.  2021
 Han Liu, Vivian Lai, and Chenhao Tan. Understanding the Effect of Out-of-distribution Examples and Interactive Explanations on Human-AI Decision Making. CSCW 2021. Ramaravind Kommiya Mothilal, Divyat Mahajan, Chenhao Tan and Amit Sharma. Towards Unifying Feature Attribution and Counterfactual Explanations: Different Means to the Same End. In Proceedings of the Fourth AAAI/ACM conference on Artificial Intelligence, Ethics, and Society (AIES&#39;2021); also presented at the Reponsible AI workshop at ICLR.</description>
    </item>
    
  </channel>
</rss>
