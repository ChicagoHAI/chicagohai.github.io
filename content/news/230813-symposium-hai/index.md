+++
title = "A Symposium on Human+AI"
date = 2023-08-13
description = """\
We are holding a [symposium on Human+AI](news/230813-symposium-hai) on Sep 29!\
"""
+++

<p>
{{% card %}}
**September 29, 2023, 9:00 AM - 5:30 PM**   
**John Crerar Library, Room 390**
{{% /card %}}
</p>

AI has achieved impressive success in a wide variety of domains, ranging from medical diagnosis to generative AI. This success provides rich opportunities for AI to address important societal challenges, but there are also growing concerns about the bias and harm that AI systems may cause. This conference brings together diverse perspectives to think about the best way for AI to fit into society and how to develop the best AI for humans. 

## Invited speakers

See [agenda](#schedule) below.


<figure class="photo" style="display:inline-block;margin:20px;">
    <img src="https://www.cs.cmu.edu/~jbigham/pics/jbigham-2023.jpg" alt="Jeffrey Bigham" style="vertical-align:top;width:120px;" />
    <figcaption style="text-align:center;">
        Jeffrey Bigham
    </figcaption>
</figure>
<figure class="photo" style="display:inline-block;margin:20px;">
    <img src="https://www.ischool.berkeley.edu/sites/default/files/styles/fullscreen/public/marti_hearst.jpg" alt="Marti Hearst" style="vertical-align:top;width:120px;" />
    <figcaption style="text-align:center;">
        Marti Hearst
    </figcaption>
</figure>
<figure class="photo" style="display:inline-block;margin:20px;">
    <img src="https://acmilab.org/uploaded_files/profile_pics/cartoon-profile-square.jpeg" alt="Zachary Lipton" style="vertical-align:top;width:120px;" />
    <figcaption style="text-align:center;">
        Zachary Lipton
    </figcaption>
</figure>
<figure class="photo" style="display:inline-block;margin:20px;">
    <img src="https://gu360.file.force.com/servlet/servlet.ImageServer?id=0151Q0000051XiMQAU&oid=00D36000000rQpzEAE" alt="Jenn Logg" style="vertical-align:top;width:120px;" />
    <figcaption style="text-align:center;">
        Jenn Logg
    </figcaption>
</figure>
<figure class="photo" style="display:inline-block;margin:20px;">
    <img src="https://sanjogmisra.com/Misra_Cartoon_Face.png" alt="Sanjog Misra" style="vertical-align:top;width:120px;" />
    <figcaption style="text-align:center;">
        Sanjog Misra
    </figcaption>
</figure>
<figure class="photo" style="display:inline-block;margin:20px;">
    <img src="images/mark_riedl.png" alt="Mark Riedl" style="vertical-align:top;width:120px;" />
    <figcaption style="text-align:center;">
        Mark Riedl
    </figcaption>
</figure>

## Registration

If you plan to attend, please fill out this one-minute survey. Registration is free. It would help us plan how much food to buy.

Please register [here](https://forms.gle/FBd1s3SW2cMULopx8) by September 15.

## Call for poster presentations

We invite all researchers and practitioners to submit poster presentations for the Symposium on Human+AI. This is an excellent opportunity to showcase your work, share insights, and engage in discussions about the intersection of AI and human society. We are particularly interested in presentations that examine opportunities and challenges to achieve complementary and beneficent AI.

Poster presenters will have the opportunity to display their posters at the Symposium and engage with fellow attendees during poster sessions. This is a chance to receive feedback, establish collaborations, and contribute to meaningful conversations about the future of interaction between humans and AI. Please submit your abstract [here](https://forms.gle/6wcXUzPBvv8tGQuHA) by September 8, 2023.

## Organization

The organizing committee for the Human + AI Conference is [Chenhao Tan](https://cs.uchicago.edu/people/chenhao-tan/), [Sendhil Mullainathan](https://www.chicagobooth.edu/faculty/directory/m/sendhil-mullainathan), and [James Evans](https://sociology.uchicago.edu/directory/james-evans). This event is made possible by generous support of the [Stevanovich Center for Financial Mathematics](https://stevanovichcenter.uchicago.edu/). [Mourad Heddaya](https://mheddaya.com) leads the program committee and [Yixuan Wang](https://am.yixuan-wang.site/) is the web master.

## Schedule

{{< grid >}}
<time>08:30 - 09:00</time>
<article>Breakfast</article>

<time>09:00 - 09:05</time>
<article>Welcome</article>

<time>09:05 - 09:55</time>
<article>
    <div><strong>Marti Hearst</strong></div>
    <div><em>Language as User Interface</em></div>
</article>

<time>09:55 - 10:45</time>
<article>
    <details>
        <summary><strong>Mark Riedl</strong></summary>
        <p>Mark Riedl is a Professor in the Georgia Tech School of Interactive Computing and Associate Director of the Georgia Tech Machine Learning Center. Dr. Riedl’s research focuses on human-centered artificial intelligence—the development of artificial intelligence and machine learning technologies that understand and interact with human users in more natural ways. Dr. Riedl’s recent work has focused on story understanding and generation, computational creativity, explainable AI, and teaching virtual agents to behave safely.</p>
    </details>
    <em>Toward Human Centered Explainable AI</em>
</article>

<time>10:45 - 11:35</time>
<article>
    <details>
        <summary><strong>Jeffery Bigham</strong></summary>
        <p>My research considers the intersection between people and machine learning broadly: I build novel human-AI systems, study how people use machine learning systems, and design possible AI futures. Much of my work focuses on accessibility because I see the field as a window into the future, given that people with disabilities are often the earliest adopters of AI. I am an Associate Professor in the Human-Computer Interaction and Language Technologies Institutes in the School of Computer Science at Carnegie Mellon University. I received my B.S.E degree in Computer Science from Princeton University in 2003, and received my Ph.D. in Computer Science and Engineering from the University of Washington in 2009. I have received the Alfred P. Sloan Foundation Fellowship (2014), the MIT Technology Review Top 35 Innovators Under 35 Award (2009), and the NSF CAREER Award (2012).</p>
    </details>
    <details>
        <summary><em>How HCI Might Engage with the Easy Access to Statistical Likelihoods of Things</em></summary>
        <p>Unintuitive statistical likelihoods of language and vision are now readily available via API, and people are connecting them to every possible way of interacting with machines. Despite this, we know both very little about and also have lots of historic precedent relevant to what interactions are likely to work, what is important for enabling them to work well, and where we should put our efforts if we want to enable better human interactions with machines. HCI thus has a vital role to play in helping us all to understand and scaffold human interaction where our intuitions fail. In this talk, I will bucket the opportunities we have as HCI researchers, using examples from my own (and others’) work in Human-AI Interaction, into themes of Benefit, Understand, Protect and Thrive.</p>
    </details>
</article>

<time>11:35 - 01:00</time>
<article>Lunch / Poster session</article>

<time>01:00 - 01:50</time>
<article>
    <div><strong>Sanjog Misra</strong></div>
    <details>
        <summary><em>Structural Deep Learning</em></summary>
        <p>Humans have an amazing ability to describe the structure of the world in ways that allows for constraints, realisms and boundaries to be respected. This structure facilitates the notion of counterfactuals which is a fundamental element of any framework that aims at making decisions. In this talk, I will discuss the need for thinking of ML and in particular deep learning as embeddable objects in structural models of human (and group or firm) behavior. I will provide some relevant contexts, examples and applications of these ideas.</p>
    </details>
</article>

<time>01:50 - 03:10</time>
<article>
    <strong>Zachary Lipton</strong>
</article>

<time>03:10 - 03:30</time>
<article>Break</article>

<time>03:30 - 04:20</time>
<article>
    <details>
        <summary><strong>Jenn Logg</strong></summary>
        <p>Jennifer M. Logg, Ph.D., is an Assistant Professor of Management at Georgetown University's McDonough School of Business. Prior to joining Georgetown, she was a Post-Doctoral Fellow at Harvard University. Dr. Logg received her Ph.D. from the University of California, Berkeley’s Haas School of Business.</p>
        <p>Her research examines why people fail to view themselves and their work realistically. It focuses on how individuals can assess themselves and the world more accurately by using advice and feedback produced by algorithms (scripts for mathematical calculations). </p>
        <p>She calls her primary line of research Theory of Machine. It uses a psychological perspective to examine how people respond to the increasing prevalence of information produced by algorithms. Broadly, this work examines how people expect algorithmic and human judgment to differ. Read more in her book chapter, The Psychology of Big Data: Developing a “Theory of Machine” to Examine Perceptions of Algorithms.</p>
        <p>She has been invited to speak on the topic of algorithms with decision-makers in the U.S. Senate, Air Force, and Navy. During her Ph.D., she was a collaborator on the Good Judgment Project, funded by IARPA, Intelligence of Advanced Research Projects Activity, the US intelligence community’s equivalent of DARPA. Currently, she is a Faculty Fellow at Georgetown University's AI, Analytics, and the Future of Work Initiative. She is also also a member of the "Theory of AI Practice" working group, funded by the Rockefeller Foundation through Stanford University's Center for Advanced Study in the Behavioral Sciences.</p>
    </details>
    <details>
        <summary><em>A Simple Explanation Reconciles “Algorithm Aversion” vs. “Algorithm Appreciation”: Hypotheticals vs. Real Judgments</em></summary>
        <p>We propose a simple explanation to reconcile research documenting algorithm aversion with research documenting algorithm appreciation: elicitation methods.  We compare self-reports and actual judgments.  When making judgments, people consistently utilize algorithmic advice more than human advice.  In contrast, hypotheticals produce unstable preferences; people sometimes report indifference and sometimes report preferring human judgment.  Moreover, people fail to correctly anticipate behavior, utilizing algorithmic advice more than they anticipate.  A framing change between hypotheticals additionally moderates algorithm aversion.  Stated preferences about algorithms are less stable than actual judgments, suggesting that algorithm aversion may be less stable than previous research leads us to believe. </p>
    </details>
</article>

<time>04:20 - 05:15</time>
<article>Panel discussion</article>
{{< /grid >}}
